# -*- coding: utf-8 -*-
"""modelos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LI6g6IQRvTmM-l0941Y9zAjmtlJAkRT2

# **MNIST DATASET**

# Baixa o dataset MNIST (70.000 imagens de 28x28 pixels)
"""

from sklearn.datasets import fetch_openml

mnist = fetch_openml("mnist_784", version=1, as_frame=False)

X = mnist["data"] # imagens (cada imagem é um vetor de 784 números: 28x28 pixels)
y = mnist["target"].astype(int) # o numero que a imagem representa (0 a 9)

"""# Criação dos vetores alvo (5 e 7)"""

y_5 = (y == 5)  # True para 5, False para outros
y_7 = (y == 7)  # True para 7, False para outros

"""# Dividir em treino (80%) e teste (20%)


"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test, y5_train, y5_test, y7_train, y7_test = train_test_split(
    X, y, y_5, y_7, test_size=0.2, random_state=42
)

"""# Função auxiliar para treinar e avaliar"""

from sklearn.metrics import confusion_matrix, precision_score, recall_score

def train_and_evaluate(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train) # Treina o modelo
    pred = model.predict(X_test) # Faz previsoes pro conjunto de teste
    cm = confusion_matrix(y_test, pred) # Matriz de Confusao
    acc = precision_score(y_test, pred) # Precisao vp/(vp+fp)
    rcc = recall_score(y_test, pred) # Revocacao vp/(vp+fn)
    return cm, acc, rcc

"""**verdadeiros negativos**: xx análises foram corretamente classificadas como não 5.

**falsos positivos**: xx foram erroneamente classificadas como 5.

**falso negativos:** xx foram classificadas erroneamente como não 5.

**verdadeiros positivos**: xx foram corretamente classificadas como 5.

**"Um classificador perfeito teria somente verdadeiros negativos e verdadeiros positivos."**

# Gradiente Descendente
"""

from sklearn.linear_model import SGDClassifier

sgd_5 = SGDClassifier(random_state=42) # Cria o modelo
sgd_5_cm, sgd_5_acc, sgd_5_rcc = train_and_evaluate(sgd_5, X_train, y5_train, X_test, y5_test)

md(f"""
## SGD - 5

### Matriz de Confusão
|| NEGATIVO | POSITIVO |
|:--:|:--:|:--:|
| VERDADEIRO | {sgd_5_cm[0][0]} | {sgd_5_cm[1][1]} |
| FALSO | {sgd_5_cm[1][0]} | {sgd_5_cm[0][1]} |

### Precisão: {sgd_5_acc*100:.2f}%
### Revocação: {sgd_5_rcc*100:.2f}%
""")

sgd_7 = SGDClassifier(random_state=42)
sgd_7_cm, sgd_7_acc, sgd_7_rcc = train_and_evaluate(sgd_7, X_train, y7_train, X_test, y7_test)

md(f"""
## SGD - 7

### Matriz de Confusão
|| NEGATIVO | POSITIVO |
|:--:|:--:|:--:|
| VERDADEIRO | {sgd_7_cm[0][0]} | {sgd_7_cm[1][1]} |
| FALSO | {sgd_7_cm[1][0]} | {sgd_7_cm[0][1]} |

### Precisão: {sgd_7_acc*100:.2f}%
### Revocação: {sgd_7_rcc*100:.2f}%
""")

"""# Naive Bayes Gaussiano

O Naive Bayes é um modelo probabilístico, ou seja, ele vai tentar calcular a chance de uma imagem ser o número 5 ou o número 7, com base nos valores dos pixels.

Ele é chamado de “naive” (“ingênuo”) porque supõe que todos os pixels são independentes entre si. O que, na prática, não é verdade, já que os pixels de uma imagem estão relacionados (formam linhas e curvas).

**Mesmo assim, essa suposição torna o modelo:**
- Muito rápido de treinar e testar;
- Muito leve computacionalmente;
- E bom como linha de base (baseline), ou seja, um ponto de partida para comparar com outros modelos.

## Como ele funciona:
Quando você mostra várias imagens de números 5 e 7, o Naive Bayes para cada pixel, ele calcula a probabilidade de estar escuro (ou claro) em imagens de 5 e de 7. Depois, quando chega uma nova imagem, ele combina essas probabilidades para decidir se a imagem tem pixels mais parecidos com o padrão dos 5 ou dos 7.
"""

from sklearn.naive_bayes import GaussianNB

gnb_5 = GaussianNB()
gnb_5_cm, gnb_5_acc, gnb_5_rcc = train_and_evaluate(gnb_5, X_train, y5_train, X_test, y5_test)

md(f"""
## GNB - 5

### Matriz de Confusão
|| NEGATIVO | POSITIVO |
|:--:|:--:|:--:|
| VERDADEIRO | {gnb_5_cm[0][0]} | {gnb_5_cm[1][1]} |
| FALSO | {gnb_5_cm[1][0]} | {gnb_5_cm[0][1]} |

### Precisão: {gnb_5_acc*100:.2f}%
### Revocação: {gnb_5_rcc*100:.2f}%
""")

gnb_7 = GaussianNB()
gnb_7_cm, gnb_7_acc, gnb_7_rcc = train_and_evaluate(gnb_7, X_train, y7_train, X_test, y7_test)

md(f"""
## GNB - 7

### Matriz de Confusão
|| NEGATIVO | POSITIVO |
|:--:|:--:|:--:|
| VERDADEIRO | {gnb_7_cm[0][0]} | {gnb_7_cm[1][1]} |
| FALSO | {gnb_7_cm[1][0]} | {gnb_7_cm[0][1]} |

### Precisão: {gnb_7_acc*100:.2f}%
### Revocação: {gnb_7_rcc*100:.2f}%
""")

"""## Exemplo de teste"""

import numpy as np

# pega uma imagem real de um 5
idx_5 = np.where(y_test == 5)[0][0]
img_5 = X_test[idx_5]
true_label_5 = y_test[idx_5]

# pega uma imagem real de um 7
idx_7 = np.where(y_test == 7)[0][0]
img_7 = X_test[idx_7]
true_label_7 = y_test[idx_7]

# previsões para "é 5?"
sgd_pred_5 = sgd_7.predict([img_5])[0]
gnb_pred_5 = gnb_7.predict([img_5])[0]

sgd_pred_7 = sgd_7.predict([img_7])[0]
gnb_pred_7 = gnb_7.predict([img_7])[0]

import matplotlib.pyplot as plt

# Exibe as imagens lado a lado
fig, axes = plt.subplots(1, 2, figsize=(8, 4))

# Imagem do 5
axes[0].imshow(img_5.reshape(28, 28), cmap="gray"7
axes[0].axis("off")
axes[0].set_title(
    f"Imagem: 5\nSGD: {'é 7' if sgd_pred_5 else 'não é 7'} | GNB: {'é 7' if gnb_pred_5 else 'não é 7'}"
)

# Imagem do 7
axes[1].imshow(img_7.reshape(28, 28), cmap="gray")
axes[1].axis("off")
axes[1].set_title(
    f"Imagem: 7\nSGD: {'é 7' if sgd_pred_7 else 'não é 7'} | GNB: {'é 7' if gnb_pred_7 else 'não é 7'}"
)

plt.tight_layout()
plt.show()

"""## Por que o desempenho é menor

**Ele teve revocação muito alta (99%), mas precisão baixa (10%), ou seja:**
- Ele acerta quase todos os 5 e 7 reais (ótima revocação);
- Mas ao mesmo tempo erra muito, marcando 5 e 7 em muitas imagens que não são 5 e 7 (baixa precisão).

**Isso acontece porque:**
- O modelo não entende a relação entre os pixels;
- E o MNIST é um conjunto de dados visual, onde o formato e o contexto dos traços importam.

### Comparando os dois modelos
- O Naive Bayes baseia-se em probabilidades
- O Gradiente Descendente busca ajustar pesos para minimizar erros.

| Critério | **Gradiente Descendente (SGD)** | **Naive Bayes** |
| :----------------- | :---------------------------------- | :-------------------------------------- |
| Tipo de modelo | Linear (baseado em pesos e erros) | Probabilístico (baseado em frequências) |
| Tempo de treino | Médio | Muito rápido |
| Interpretação | Aprende padrões mais complexos | Simples, mas limitado |
| Precisão esperada  | Alta | Baixa |
| Revocação esperada | Boa | Alta (mas com falsos positivos) |
| Ideal para | Dados contínuos, imagens, regressão | Texto, e-mails, spam, categóricos |
| No MNIST (5 vs 7) | Melhor desempenho | Serve como base de comparação |

# **PLANILHA LOGÍSTICA DE SERVIÇO PREDIAL**

# Leitura e visualização da base de dados
"""

import pandas as pd

path = '/content/drive/MyDrive/dadosLog.xlsx'

df = pd.read_excel(path)
df.head()

"""# Pré-processamento"""

# Remoção de colunas sem nome
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

# Remoção das aspas extras no nome da coluna cod_chamado
df = df.rename(columns={df.columns[0]: 'cod_chamado'})

# Remoção dos chamados duplicados (mantendo a modificação mais recente), deletados
df = df.sort_values('dat_modificacao', ascending=False)
df = df.drop_duplicates(subset='cod_chamado', keep='first').reset_index(drop= True)

df = df.drop(df[df['des_status'] == 'deleted'].index)

# Preencher chamados com status "solved" e dat_resolucao vazia com a data da última modificação
cond1 = (df['des_status'].str.lower() == 'solved') & (df['dat_resolucao'].isna())
df.loc[cond1, 'dat_resolucao'] = df.loc[cond1, 'dat_modificacao']

# Preencher chamados com status "closed" e dat_conslusao vazia com a data de resolução
cond2 = (df['des_status'].str.lower() == 'closed') & (df['dat_conclusao'].isna())
df.loc[cond2, 'dat_conclusao'] = df.loc[cond1, 'dat_resolucao']

# Visualização da base de dados tratada
print('colunas do DataFrame:', df.columns.tolist())
df.head()

"""A planilha se trata de um dataset de chamados (tickets) de um sistema de atendimento/gestão operacional, ligado a manutenção predial, operações logísticas, facilities... É uma lista de chamados abertos por clientes/usuarios para reportar problemas, solicitar serviços ou registrar incidentes em um ambiente operacional.

### Ela contém:
- Informações do chamado
- Status e datas
- Identificadores internos (IDs de marca, grupo, formulário, usuários…)
- Informações sobre cliente e solicitante
- Informações complementares de atendimento e incidentes

### Principais colunas que serão utilizadas:
- des_chamado: descrição do tipo de pedido de manutenção
- des_prioridade: grau de urgência do chamado (low, normal, high, urgent)

# Aplicação do modelo

Para o exemplo, vamos supor que a tarefa seja prever o grau de urgência do chamado a partir do tipo de pedido de manutenção.

## Preparação
"""

# Selecionar apenas linhas que possuem tipo de pedido de manutenção
df_predial = df[df['des_prioridade'].notna()].copy()

X = df_predial['des_chamado']
y = df_predial['des_prioridade']

# Vetorização com TF-IDF
import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stopwords_pt = stopwords.words("portuguese")

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words=stopwords_pt, max_features=5000)

X_vec = vectorizer.fit_transform(X)

# Split train/test
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_vec, y, test_size=0.2, random_state=42
)

df_predial[['des_chamado', 'des_prioridade']].head()

"""## Naive Bayes Multinominal

Nesse caso vamos utilizar o Naive Bayes Multinominal que também se baseia em probabilidade, é simples e rápido, porém é mais adequado para lidar com dados textuais. Diferente do Naive Bayes Gaussiano, que é indicado para dados numéricos contínuos.
"""

from sklearn.naive_bayes import MultinomialNB

nb = MultinomialNB() # Cria o modelo
nb.fit(X_train, y_train) # Treina o modelo
acc_nb = nb.score(X_test, y_test) # Calcula a porcentagem de acerto

md(f"""
### Acurácia: {acc_nb*100:.2f}%
""")

"""## Exemplo de teste"""

tipo = [
    "Revitalização pintura da sala de descanso da equipe. Material e mão de obra conforme orçamento."
]

vec = vectorizer.transform(tipo)

md(f"""
  ### Previsão: {nb.predict(vec)[0]}
""")

"""# Conclusão

O modelo Naive Bayes Multinomial apresentou uma acurácia de 93%, demonstrando excelente capacidade de prever o grau de urgência dos chamados com base na descrição do tipo de pedido de manutenção.
Durante o teste prático, o modelo classificou o pedido “Revitalização pintura da sala de descanso da equipe. Material e mão de obra conforme orçamento.” como de prioridade normal, o que condiz com o contexto, já que se trata de um serviço estético, sem caráter emergencial.

Esses resultados indicam que o modelo é capaz de aprender e generalizar bem os padrões de urgência a partir das palavras presentes nas descrições dos chamados. Assim, ele pode ser utilizado como uma ferramenta de apoio à decisão, auxiliando na validação automática de pedidos urgentes e na priorização de atendimentos de forma mais eficiente e confiável.
"""